# -*- coding: utf-8 -*-
from __future__ import absolute_import
from __future__ import unicode_literals

import six
from luigi.contrib import postgres

from .credentials import PostgresCredentialsMixin
from .migrations import MigrateMetabaseSchema


class CopyToMetabaseTable(PostgresCredentialsMixin, postgres.CopyToTable):
    """
    Inserts data from CSV into given table.
    Data source has to be defined with a 'data'-key in the require method
    """

    def requires(self):
        return {
            'migration': MigrateMetabaseSchema()
        }

    def rows(self):
        """
        Return/yield tuples or lists corresponding to each row to be inserted.
        """
        with self.input()['data'].open('r') as input:
            for row in input:
                yield row


class UpsertDataToManyTables(CopyToMetabaseTable):
    """
    Upserts data from many data sources into many tables.
    It also deactivates the foreign key checks on the upsert for non-conflict insert of depending data.

    Usage:
    define a member called tables in the following structure for one or more tables to be upserted into
    including the columns that should be inserted. They have to match the target table and the csv input:

    tables = {
        'TABLENAME1' : {
            'columns': (
                'COLUMNNAME1',
                'COLUMNNAME2',
                'COLUMNNAME3',
                ...
            ),
            'match_on': 'UNIQUE_COLUMN' for single constrainted column
                        or ('UNIQUE_COLUMN1', 'UNIQUE_COLUMN2') for multiple uniquenes constraints
        },
        'TABLENAME2': ...
    }

    The columns that should be matched on have to be set to uinque on the db level

    The input for the upserts is taken from the required() method.
    There you should define the data sources as dict as follows:

    {
        'TABLENAME1': ExtractDataFromDBTable1(),
        'TABLENAME2': ExtractDataFromDBTable2()
    }
    """
    def _is_number(self, s):
        try:
            float(s)
            return True
        except ValueError:
            return False

    def _cleanup_row(self, row):
        """
        NULL values are empty string in CSV
        We have to convert them to None to work correctly in the upnsert
        (None will be inserted as NULL)
        """
        nulled_row = (None if not v else v for v in row)
        return nulled_row

    def _get_placeholders(self, columns, string_format):
        placeholders = [string_format.format(i + 1) for i in xrange(0, len(columns))]
        return ', '.join(placeholders)

    def _get_plan_placeholders(self, columns):
        return self._get_placeholders(columns, '${}')

    def _get_execution_placeholders(self, columns):
        return self._get_placeholders(columns, '%s')

    def _create_where_clause(self, table, match_on):
        conditions = ['{table}.{match_on} = EXCLUDED.{match_on}'.format(table=table, match_on=m) for m in match_on]
        return ' AND '.join(conditions)

    def table_rows(self, table):
        """
        Return/yield tuples or lists corresponding to each row to be inserted.
        """
        with self.input()[table].open('r') as input:
            for row in input:
                yield row

    def after_upsert(self, cursor):
        """
        Execute special queries after all upserts are finished
        """
        pass

    def run(self):
        """
        Upserts data generated by rows() into target table.
        """

        connection = self.output().connect()
        cursor = connection.cursor()
        cursor.execute("SET CONSTRAINTS ALL DEFERRED")

        for table, tableconfig in self.tables.iteritems():

            if not ('columns' in tableconfig and 'match_on' in tableconfig):
                raise Exception('Each table need columns and match_on to be specified')

            cleaned_match_on = (tableconfig['match_on'],) if isinstance(tableconfig['match_on'], six.string_types) else \
                tableconfig['match_on']

            data = {
                'columns': ', '.join(tableconfig['columns']),
                'table': table,
                'match_on_conflict': ', '.join(cleaned_match_on),
                'match_on_update_where': self._create_where_clause(table, cleaned_match_on),
                'plan_placeholders': self._get_plan_placeholders(tableconfig['columns'])
            }

            cursor.execute(
                """
                PREPARE upsert_{table} AS
                INSERT INTO {table} ({columns}) VALUES ({plan_placeholders})
                ON CONFLICT ({match_on_conflict}) DO
                UPDATE SET ({columns}) = ({plan_placeholders}) WHERE {match_on_update_where}
                """.format(**data)
            )

            for row in self.table_rows(table):
                sql = 'EXECUTE upsert_{table} ({placeholders})' \
                    .format(placeholders=self._get_execution_placeholders(tableconfig['columns']), table=table)
                try:
                    cursor.execute(sql, list(self._cleanup_row(row)))
                except IndexError, ex:
                    # FIXME: show which table, columns and dataset in exception
                    print "Wrong column count in list for table {}.".format(table)
                    raise ex

            self.after_upsert(cursor)

        # mark as complete in same transaction
        self.output().touch(connection)

        # commit and clean up
        connection.commit()
        connection.close()


class UpsertDataToTable(UpsertDataToManyTables):
    """
    Thats a helper class to use only one data source and one table to upsert data
    Define table, colums and match_on as members on the class.

    You still have to require the data sources like described in UpsertDataToManyTables
    """

    def run(self):
        """
        Upserts data generated by rows() into target table.
        """
        if not (self.table and self.columns and self.match_on):
            raise Exception("table, columns and match_on need to be specified")

        self.tables = {
            self.table: {
                'columns': self.columns,
                'match_on': self.match_on
            }
        }

        return super(UpsertDataToTable, self).run()
